{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "441bc651",
   "metadata": {},
   "source": [
    "## explore HF gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba87e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2') # gpt2-medium, gpt2-large, gpt2-xl\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "sd_hf = model.state_dict()\n",
    "for k, v in sd_hf.items():\n",
    "    print(f'{k} --> {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec0631",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hi, I'm a language model,\"\n",
    "input_ids = tokenizer(prompt, return_tensors='pt')['input_ids']\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd28c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = dict(\n",
    "    max_new_tokens=30,\n",
    "    do_sample=True,\n",
    "    top_k=50,            # pipeline default\n",
    "    top_p=0.95,          # pipeline default\n",
    "    temperature=1.0,\n",
    "    num_return_sequences=2,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "output_ids = model.generate(input_ids, **gen_kwargs)\n",
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tok.decode(output_ids[0])\n",
    "print(\"> \", tokenizer.decode(output_ids[0], skip_special_tokens=True))\n",
    "print(\"> \", tokenizer.decode(output_ids[1], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd01a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "# set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", num_return_sequences=2, max_new_tokens=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa028343",
   "metadata": {},
   "source": [
    "## weight tying property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sd_hf['transformer.wte.weight'].shape, sd_hf['lm_head.weight'].shape)\n",
    "print((sd_hf['transformer.wte.weight'] == sd_hf['lm_head.weight']).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca06617",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sd_hf['transformer.wte.weight'].data_ptr())\n",
    "print(sd_hf['lm_head.weight'].data_ptr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef1c27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aed6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "936fb455",
   "metadata": {},
   "source": [
    "## causal self attention elaborate affinity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a3e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "b,t,c = 2,3,4\n",
    "nh,hs = 2,2\n",
    "qkv = torch.randn((b,t,3*c))\n",
    "q,k,v = qkv.split(c, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(qkv[:,:,:c], q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.shape, q.view(b,t,nh,hs).shape, q.view(b,t,nh,hs).transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9a92fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.view(b,nh,t,hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc03bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = q.view(b,t,nh,hs).transpose(1,2)\n",
    "k = k.view(b,t,nh,hs).transpose(1,2)\n",
    "v = v.view(b,t,nh,hs).transpose(1,2)\n",
    "\n",
    "affinity_scores = (q @ k.transpose(-2,-1)) # (b,nh,t,t)\n",
    "affinity_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa372f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(t,t, dtype=torch.long))\n",
    "tril # (t,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c29dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity_scores = (q @ k.transpose(-2,-1)) # (b,nh,t,t)\n",
    "tril = torch.tril(torch.ones(t,t, dtype=torch.long))\n",
    "\n",
    "affinity_scores = affinity_scores.masked_fill(tril==0, float('-inf'))\n",
    "affinity_scores = torch.nn.functional.softmax(affinity_scores, dim=-1)\n",
    "affinity_scores # (b,nh,t,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52df3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = affinity_scores @ v # (b,nh,t,t) @ (b,nh,t,hs) -> (b,nh,t,hs)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251738b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.view(b,t,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c12031",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.transpose(1,2).contiguous().view(b,t,c)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5036c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff081a3",
   "metadata": {},
   "source": [
    "## input data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    devide = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('input.txt', 'r').read()\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sample = text[:1000]\n",
    "\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(text_sample)\n",
    "tokens = torch.tensor(tokens, dtype=torch.long, device=device)\n",
    "print(tokens[:24+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7230c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a single batch of batch_size = 4\n",
    "B,T = 4,6\n",
    "tokens_sample = tokens[:B*T+1]\n",
    "x = tokens_sample[:-1].view(B,T).to(device)\n",
    "y = tokens_sample[1:].view(B,T).to(device)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ff5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2 import GPT2, GPT2Config\n",
    "config = GPT2Config()\n",
    "model = GPT2(config=config).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7390df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, loss  = model(x,y)\n",
    "print(logits.shape) # 4,6,50257\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b37cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    logits, loss = model(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%10 == 0:\n",
    "        print(f'iteration: {i} --> loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a157f8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
